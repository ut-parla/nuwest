{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "# Tutorial 04: Data Movement\n",
    "\n",
    "This tutorial introduces how to move data between devices. \n",
    "- Data Movement - `clone_here` and `copy`, \n",
    "- Prefetched Data Movement - via Parla Managed Arrays (PArrays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "from time import perf_counter, sleep\n",
    "import os\n",
    "\n",
    "def set_numpy_threads(threads: int = 1):\n",
    "    \"\"\"\n",
    "    Numpy can be configured to use multiple threads for linear algebra operations.\n",
    "    The backend used by numpy can vary by installation.\n",
    "    This function attempts to set the number of threads for the most common backends.\n",
    "    MUST BE CALLED BEFORE IMPORTING NUMPY.\n",
    "\n",
    "    Args:\n",
    "        threads (int, optional): The number of threads to use. Defaults to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = str(threads)\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(threads)\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = str(threads)\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(threads)\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = str(threads)\n",
    "\n",
    "    try:\n",
    "        # Controlling the MKL backend can use mkl and mkl-service modules if installed.\n",
    "        # preferred method for controlling the MKL backend.\n",
    "        import mkl\n",
    "\n",
    "        mkl.set_num_threads(threads)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "set_numpy_threads(1)\n",
    "import numpy as np \n",
    "import cupy as cp \n",
    "\n",
    "# Handle for Parla runtime\n",
    "from parla import Parla\n",
    "\n",
    "# Spawning task API\n",
    "from parla.tasks import (\n",
    "    spawn,\n",
    "    TaskSpace,\n",
    "    get_current_context,\n",
    "    get_current_task,\n",
    ")\n",
    "\n",
    "# Device Architectures for placement\n",
    "from parla.devices import cpu, gpu\n",
    "\n",
    "\n",
    "def run(function: Callable[[], Optional[TaskSpace]]):\n",
    "    assert callable(function), \"The function argument must be callable.\"\n",
    "\n",
    "    # Start the Parla runtime.\n",
    "    with Parla():\n",
    "        # Create a top-level task to kick off the computation\n",
    "        @spawn(placement=cpu, vcus=0)\n",
    "        async def top_level_task():\n",
    "            # Note that unless function returns a TaskSpace, this will NOT be blocking.\n",
    "            # If you want to wait on the completion of the tasks launched by function, you must return a TaskSpace that contains their terminal tasks.\n",
    "            await function()\n",
    "\n",
    "    # Runtime exists at the end of the context_manager\n",
    "    # All tasks are guaranteed to be complete at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parla.array import clone_here, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(global_1)  running on  GPUEnvironment(GPU:0)\n",
      "C is a Cupy Array on GPU[<CUDA Device 0>]\n",
      "B =  [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "def clone_here_copy_example_wrapper():\n",
    "    import numpy as np\n",
    "    import cupy as cp\n",
    "    M = 5\n",
    "    N = 5\n",
    "    A = np.random.rand(M)\n",
    "    B = cp.arange(N)\n",
    "    \n",
    "    def clone_here_copy_example():\n",
    "        T = TaskSpace(\"T\")\n",
    "        \n",
    "        @spawn(placement=[cpu if np.random.rand() < 0.5 else gpu])\n",
    "        def task():\n",
    "            print(get_current_task(), \" running on \", get_current_context())\n",
    "            C = clone_here(A)\n",
    "            print(\"C is a\", \"Numpy Array\" if isinstance(C, np.ndarray) else f\"Cupy Array on GPU[{C.device}]\", flush=True)\n",
    "            \n",
    "            # Writing back to B from any source\n",
    "            # TODO: FIX!\n",
    "            # copy(B, C[:N])\n",
    "            \n",
    "        return T\n",
    "    \n",
    "    run(clone_here_copy_example)\n",
    "    \n",
    "    print(\"B = \", B, flush=True)\n",
    "        \n",
    "clone_here_copy_example_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parla.array import asarray as parla_asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running data movement task: b'global_1.dm.0', NA 0\n",
      "Task(global_1)  running on  GPUEnvironment(GPU:0)\n",
      "A is a Cupy Array on GPU[<CUDA Device 0>]\n",
      "---Overview of PArray\n",
      "ID: 133866630519392, Name: NA, Parent_ID: None, Slice: None, Bytes: 40, Owner: GPU 0\n",
      "At GPU 0: state: SHARED\n",
      "At CPU: state: SHARED\n",
      "---End of Overview\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "async def parray_example():\n",
    "\n",
    "    A = np.random.rand(5)\n",
    "    A = parla_asarray(A)\n",
    "\n",
    "    @spawn(placement=[cpu if np.random.rand() < 0.5 else gpu], input=[A])\n",
    "    def task():\n",
    "        print(get_current_task(), \" running on \", get_current_context())\n",
    "        print(\n",
    "            \"A is a\",\n",
    "            \"Numpy Array\"\n",
    "            if isinstance(A.array, np.ndarray)\n",
    "            else f\"Cupy Array on GPU[{A.array.device}]\",\n",
    "            flush=True,\n",
    "        )\n",
    "        A.print_overview()\n",
    "\n",
    "\n",
    "run(parray_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running data movement task: b'T_0.dm.0', NA 0\n",
      "Running data movement task: b'T_1.dm.0', NA 2\n",
      "Task(T_0)  running on  GPUEnvironment(GPU:0)\n",
      "Exception in Task  Task(T_0) :  'NoneType' object has no attribute 'device' Traceback (most recent call last):\n",
      "  File \"tasks.pyx\", line 472, in parla.cython.tasks.Task.run\n",
      "  File \"tasks.pyx\", line 661, in parla.cython.tasks.ComputeTask._execute_task\n",
      "  File \"scheduler.pyx\", line 494, in parla.cython.scheduler._task_callback\n",
      "  File \"/tmp/ipykernel_311020/3928032198.py\", line 14, in task\n",
      "    else f\"Cupy Array on GPU[{A.array.device}]\",\n",
      "                              ^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'device'\n",
      "\n",
      "Exception in Worker Thread  <WorkerThread(Thread-651, started 133865918154304)> :  'NoneType' object has no attribute 'device' Traceback (most recent call last):\n",
      "  File \"scheduler.pyx\", line 196, in parla.cython.scheduler.WorkerThread.run\n",
      "  File \"scheduler.pyx\", line 273, in parla.cython.scheduler.WorkerThread.run\n",
      "parla.cython.scheduler.TaskBodyException: 'NoneType' object has no attribute 'device'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-651:\n",
      "Traceback (most recent call last):\n",
      "  File \"scheduler.pyx\", line 196, in parla.cython.scheduler.WorkerThread.run\n",
      "  File \"scheduler.pyx\", line 273, in parla.cython.scheduler.WorkerThread.run\n",
      "parla.cython.scheduler.TaskBodyException: 'NoneType' object has no attribute 'device'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wlruys/software/miniforge3/envs/py312/lib/python3.12/threading.py\", line 1052, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"scheduler.pyx\", line 327, in parla.cython.scheduler.WorkerThread.run\n",
      "parla.cython.scheduler.WorkerThreadException: Unhandled Exception in Task: T_0\n"
     ]
    }
   ],
   "source": [
    "async def parray_example():\n",
    "    T = TaskSpace(\"T\")\n",
    "\n",
    "    A = np.ones(5)\n",
    "    A = parla_asarray(A)\n",
    "\n",
    "    @spawn(T[0], placement=[cpu if np.random.rand() < 0.5 else gpu], input=[A])\n",
    "    def task():\n",
    "        print(get_current_task(), \" running on \", get_current_context())\n",
    "        print(\n",
    "            \"A is a\",\n",
    "            \"Numpy Array\"\n",
    "            if isinstance(A.array, np.ndarray)\n",
    "            else f\"Cupy Array on GPU[{A.array.device}]\",\n",
    "            flush=True,\n",
    "        )\n",
    "        A.print_overview()\n",
    "        print(A.array)\n",
    "\n",
    "    @spawn(T[1], [T[0]], placement=[cpu if np.random.rand() < 0.5 else gpu], inout=[A])\n",
    "    def task():\n",
    "        print(get_current_task(), \" running on \", get_current_context())\n",
    "        print(\n",
    "            \"A is a\",\n",
    "            \"Numpy Array\"\n",
    "            if isinstance(A.array, np.ndarray)\n",
    "            else f\"Cupy Array on GPU[{A.array.device}]\",\n",
    "            flush=True,\n",
    "        )\n",
    "        A.print_overview()\n",
    "        A[:] = A + 1\n",
    "\n",
    "    @spawn(T[2], [T[0], T[1]], placement=[cpu if np.random.rand() < 0.5 else gpu], inout=[A])\n",
    "    def task():\n",
    "        print(get_current_task(), \" running on \", get_current_context())\n",
    "        print(\n",
    "            \"A is a\",\n",
    "            \"Numpy Array\"\n",
    "            if isinstance(A.array, np.ndarray)\n",
    "            else f\"Cupy Array on GPU[{A.array.device}]\",\n",
    "            flush=True,\n",
    "        )\n",
    "        A.print_overview()\n",
    "        print(A.array)\n",
    "\n",
    "\n",
    "run(parray_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
