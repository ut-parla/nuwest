{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "# Tutorial 02: Control Flow\n",
    "\n",
    "This tutorial introduces basic concepts in task-based parallel programming using Parla.\n",
    "We will cover:\n",
    "- TaskSpaces (NamedTasks)\n",
    "- Task Dependencies\n",
    "- Barrier synchronization\n",
    "\n",
    "First, let's configure the tutorial environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "from time import perf_counter, sleep\n",
    "\n",
    "# Handle for Parla runtime\n",
    "from parla import Parla\n",
    "\n",
    "# Spawning  tasks\n",
    "from parla.tasks import spawn, TaskSpace\n",
    "from parla.devices import cpu\n",
    "\n",
    "\n",
    "def run(function: Callable[[], Optional[TaskSpace]]):\n",
    "    assert callable(function), \"The function argument must be callable.\"\n",
    "\n",
    "    # Start the Parla runtime.\n",
    "    with Parla():\n",
    "        # Create a top-level task to kick off the computation\n",
    "        @spawn(placement=cpu, vcus=0)\n",
    "        async def top_level_task():\n",
    "            # Note that unless function returns a TaskSpace, this will NOT be blocking.\n",
    "            # If you want to wait on the completion of the tasks launched by function, you must return a TaskSpace that contains their terminal tasks.\n",
    "            await function()\n",
    "\n",
    "    # Runtime exists at the end of the context_manager\n",
    "    # All tasks are guaranteed to be complete at this point\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referring to Tasks\n",
    "\n",
    "### Unnamed Tasks. \n",
    "#### Example: `tutorial/04_unnamed_tasks.py`\n",
    "\n",
    "As we saw in the first tutorial, we can create tasks using the `spawn` decorator.\n",
    "If the task is not given a name explicitly, it is assigned a unique name in Parla's default global namespace. \n",
    "\n",
    "The function handle that was decorated by `@spawn` provides a reference to the task. \n",
    "\n",
    "When running code inside of a task, a reference to the active task can always be obtained using `parla.task.get_current_task()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anonymous_tasks...\n",
      "Hello from Task Task(global_1)! \n",
      "\n",
      "Hello from Task Task(global_2)! \n",
      "\n",
      "Hello from Task Task(global_4)! \n",
      "\n",
      "Hello from Task Task(global_3)! \n",
      "\n",
      "List of Tasks:  [Task(global_1), Task(global_2), Task(global_3), Task(global_4)]\n"
     ]
    }
   ],
   "source": [
    "from parla.tasks import get_current_task \n",
    "\n",
    "async def anonymous_tasks():\n",
    "    list_of_tasks = []\n",
    "    for i in range(4):\n",
    "        @spawn()\n",
    "        def task():\n",
    "            my_name = get_current_task()\n",
    "            print(f\"Hello from Task {my_name}! \\n\", flush=True)\n",
    "        \n",
    "        list_of_tasks.append(task)\n",
    "        \n",
    "    sleep(0.1)\n",
    "        \n",
    "    print(\"List of Tasks: \", list_of_tasks, flush=True)\n",
    "\n",
    "print(\"Running anonymous_tasks...\")\n",
    "run(anonymous_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### TaskSpaces\n",
    "\n",
    "**TaskSpaces** are an indexable collection of tasks. They provide a namespace for Task IDs. \n",
    "\n",
    "Every spawned task must have a **unique** identifier within the TaskSpace it is spawned in.\n",
    "Two spawned tasks cannot be linked to the same underlying reference.  \n",
    "\n",
    "#### Example: `tutorial/04_named_tasks.py`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running named_tasks...\n",
      "Hello from Task(T_0)! \n",
      "\n",
      "Hello from Task(T_2)! \n",
      "\n",
      "Hello from Task(T_3)! \n",
      "\n",
      "Hello from Task(T_1)! \n",
      "\n",
      "TasksSpace:  TaskSpace(T, ntasks=4)\n",
      "Contains:  [Task(T_0), Task(T_1), Task(T_2), Task(T_3)]\n"
     ]
    }
   ],
   "source": [
    "from parla import TaskSpace\n",
    "\n",
    "async def named_tasks():\n",
    "    \n",
    "    T = TaskSpace(\"T\")\n",
    "    n_tasks = 4\n",
    "    for i in range(n_tasks):\n",
    "        @spawn(T[i])\n",
    "        def task():\n",
    "            print(f\"Hello from {T[i]}! \\n\", flush=True)\n",
    "    sleep(0.1)\n",
    "    print(\"TasksSpace: \", T)\n",
    "    print(\"Contains: \", list(T.tasks), flush=True)\n",
    "    \n",
    "print(\"Running named_tasks...\")\n",
    "run(named_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaskSpaces can be indexed by any hashable type. Although we recommend sticking to integers and slices for interpretability and performance.\n",
    "\n",
    "\n",
    "#### Example: `tutorial/05_taskspace_slicing.py`\n",
    "They can be sliced, are iterable, and can be indexed in arbitrary dimension.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running taskspace_slicing...\n",
      "Hello from Task(T_0_0)! \n",
      "\n",
      "Hello from Task(T_1_1)! \n",
      "\n",
      "Hello from Task(T_1_0)! \n",
      "\n",
      "Hello from Task(T_0_1)! \n",
      "\n",
      "TasksSpace:  TaskSpace(T, ntasks=4)\n",
      "Slice of Tasks:  TaskList: [Task(T_0_0), Task(T_0_1)]\n",
      "State of Task[0, 0]:  TaskCompleted(None)\n"
     ]
    }
   ],
   "source": [
    "async def taskspace_slicing():\n",
    "    T = TaskSpace(\"T\")\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            @spawn(T[i, j])\n",
    "            def task():\n",
    "                print(f\"Hello from {T[i, j]}! \\n\", flush=True)\n",
    "    \n",
    "    sleep(0.1)\n",
    "    print(\"TasksSpace: \", T)\n",
    "    print(\"Slice of Tasks: \", T[0:1, 0:2], flush=True)\n",
    "    print(\"State of Task[0, 0]: \", T[0, 0].state, flush=True)\n",
    "\n",
    "print(\"Running taskspace_slicing...\")\n",
    "run(taskspace_slicing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "\n",
    "## Task Dependencies\n",
    "\n",
    "Once a reference for a task is available it can be used to create dependencies between tasks.\n",
    "This is the second argument to the `spawn` decorator.\n",
    "\n",
    "Tasks can depend on any other task, in any TaskSpace.\n",
    "\n",
    "Generally, tasks will not be launched until all of their dependencies have completed.\n",
    "\n",
    "*Note: That this is not a strict requirement when allowing event driven submission of tasks to hardware queues (CUDA streams) \"Runahead Scheduling\".*\n",
    "\n",
    "\n",
    "#### Example: `tutorial/06_dependencies.py`\n",
    "\n",
    "Below we show a serial chain of tasks.\n",
    "\n",
    "TaskSpaces have boundaries and a shape when indexed by integers. \n",
    "By default, a TaskSpace will only may only contain positive Task IDs,  [0, inf) along each dimension.\n",
    "Indexes outside of the boundary will return empty references. \n",
    "This allows easy handling of base cases and boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running serial_tasks...\n",
      "Hello from Task(T_0)! \n",
      "\n",
      "Hello from Task(T_1)! \n",
      "\n",
      "Hello from Task(T_2)! \n",
      "\n",
      "Hello from Task(T_3)! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def serial_tasks():\n",
    "    T = TaskSpace(\"T\")\n",
    "\n",
    "    for i in range(4):\n",
    "        @spawn(T[i], dependencies=[T[i-1]]) # Could also have written dependencies=T[:i]\n",
    "        def task():\n",
    "            print(f\"Hello from {T[i]}! \\n\", flush=True)\n",
    "            \n",
    "print(\"Running serial_tasks...\")\n",
    "run(serial_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: `tutorial/07_dependencies_reduction.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running task_reduction_dependencies...\n",
      "Initial array:  [0 1 2 3 4 5 6 7]\n",
      "Expected sum:  28\n",
      "Final array:  [28  1  5  3 22  5 13  7]\n",
      "Sum:  28\n"
     ]
    }
   ],
   "source": [
    "async def task_reduction_dependencies():\n",
    "    import numpy as np\n",
    "\n",
    "    T = TaskSpace(\"T\")\n",
    "\n",
    "    N = 8\n",
    "    levels = int(np.log2(N))\n",
    "\n",
    "    array = np.arange(N)\n",
    "    expected_sum = np.sum(array)\n",
    "\n",
    "    scratch = {}\n",
    "    scratch[0] = array\n",
    "    for level in range(1, levels):\n",
    "        length = int(N / 2 ** (level + 1))\n",
    "        scratch[level] = np.zeros(length)\n",
    "\n",
    "    print(\"Initial array: \", array, flush=True)\n",
    "    print(\"Expected sum: \", expected_sum, flush=True)\n",
    "\n",
    "    # Generate tasks for a reduction tree\n",
    "    for level in range(levels):\n",
    "        stride = int(2 ** (level + 1))\n",
    "        for idx in range(0, N, stride):\n",
    "            writes_to = idx\n",
    "            reads_from = idx + stride // 2\n",
    "\n",
    "            @spawn(T[level, writes_to], [T[level - 1, reads_from]])\n",
    "            def task():\n",
    "                array[writes_to] += array[reads_from]\n",
    "\n",
    "    # Wait for the reduction tree to finish\n",
    "    await T[levels - 1, 0]\n",
    "\n",
    "    print(\"Final array: \", array, flush=True)\n",
    "    print(\"Sum: \", array[0], flush=True)\n",
    "\n",
    "\n",
    "print(\"Running task_reduction_dependencies...\")\n",
    "run(task_reduction_dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced TaskSpaces\n",
    "\n",
    "As mentioned above, TaskSpaces can be given arbitrary shapes and boundaries.\n",
    "This allows for more tunable handling and safety when indexing.\n",
    "\n",
    "TaskSpace slicing is *dense*. It creates a handle for a task on first access.\n",
    "This means that when indexing a TaskSpace, it will always return a reference to a task, even if it has not been created yet.\n",
    "This is useful for creating dependencies on tasks that may not have been created yet.\n",
    "Note that this can be dangerous if the task is never created, as it will create a hanging dependency that will never be satisfied.\n",
    "\n",
    "#### Example: `tutorial/08_advanced_taskspace_boundaries.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaped TaskSpace slicing on T1\n",
      "TasksSpace:  TaskList: [Task(T1_0_0), Task(T1_0_1), Task(T1_1_0), Task(T1_1_1)]\n",
      "Summary:  TaskSpace(T1, ntasks=4)\n",
      "---\n",
      "Handle Creation on T2\n",
      "TasksSpace:  Task(T2_0_0) Task(T2_1_1)\n",
      "Summary:  TaskSpace(T2, ntasks=2)\n",
      "---\n",
      "Sparse Access on T2[:, :]\n",
      "TaskList: [Task(T2_0_0), Task(T2_1_1)]\n"
     ]
    }
   ],
   "source": [
    "async def taskspace_boundaries_and_access():\n",
    "    T1 = TaskSpace(\"T1\", shape=(2, 2))\n",
    "\n",
    "    # TaskSpace with shape (2, 2) has 4 possible integer indices\n",
    "    print(\"Shaped TaskSpace slicing on T1\")\n",
    "    print(\"TasksSpace: \", T1[:, :])\n",
    "    print(\"Summary: \", T1)\n",
    "    print(\"---\")\n",
    "    \n",
    "\n",
    "    # TaskSpace slicing is *dense*. It creates a handle for a task on first access.\n",
    "    T2 = TaskSpace(\"T2\", shape=(2, 2))\n",
    "    print(\"Handle Creation on T2\")\n",
    "    print(\"TasksSpace: \", T2[0, 0], T2[1, 1])\n",
    "    print(\"Summary: \", T2)\n",
    "    print(\"---\")\n",
    "    \n",
    "    # Sparse access is possible with TaskSpace.view \n",
    "    # This will only return handles that already exist \n",
    "    print(\"Sparse Access on T2[:, :]\")\n",
    "    print(T2.view[:, :])\n",
    "\n",
    "\n",
    "run(taskspace_boundaries_and_access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: `tutorial/09_out_of_order_spawn.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from task0!\n",
      "Hello from task1!\n"
     ]
    }
   ],
   "source": [
    "async def out_of_order():\n",
    "    T = TaskSpace(\"T\")\n",
    "    \n",
    "    @spawn(T[1], [T[0]])\n",
    "    def task1():\n",
    "        print(\"Hello from task1!\", flush=True)\n",
    "        \n",
    "    @spawn(T[0])\n",
    "    def task0():\n",
    "        print(\"Hello from task0!\", flush=True)\n",
    "\n",
    "\n",
    "run(out_of_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barriers and Synchronization\n",
    "\n",
    "Barriers are used to synchronize execution of tasks. They block a task's execution until all tasks listed in the barrier have completed.\n",
    "Parla's barrier semantics are based on the Python async API model. \n",
    "\n",
    "This means any task that contains a barrier must be declared `async def` and spawned normally with `@spawn`.\n",
    "\n",
    "Barriers are a special (implicit) type of dependency. \n",
    "When a task encounters a barrier, it will release control of its worker thread and spawn a new continuation of itself as a new separate task. \n",
    "This continuation task will depend on all tasks listed in the barrier and will not be launched until all of them have completed.\n",
    "\n",
    "As a consequence, Barriers can only be used within tasks and cannot be used in the outermost non-task scope.\n",
    "This is why our `run` function contains a top-level task. \n",
    "\n",
    "*Note: Reaching an await statement will release a tasks worker thread and non-persistent resources.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from task 0!\n",
      "Hello from task 1!\n",
      "Hello from task 2!\n",
      "Hello from task 3!\n"
     ]
    }
   ],
   "source": [
    "async def simple_barrier():\n",
    "    T = TaskSpace(\"T\")\n",
    "    \n",
    "    for i in range(4):\n",
    "        @spawn(T[i])\n",
    "        def task1():\n",
    "            print(f\"Hello from task {i}!\", flush=True)\n",
    "            \n",
    "        await T\n",
    "        \n",
    "run(simple_barrier)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
